{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe739b8",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df3d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen as cj\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde760d9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba6bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv with the US market data\n",
    "data = pd.read_csv('US_market.csv', index_col = 0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "# Taking only the tickers with less than a certain percentage threshold of NA\n",
    "threshold = 0.0032\n",
    "mask = np.array(data.isna().sum()/data.shape[0]) < threshold\n",
    "df = data.iloc[:,mask]\n",
    "\n",
    "df = df.fillna(method = 'ffill')\n",
    "df = df.fillna(method = 'bfill')\n",
    "\n",
    "columns_duplicated = [elem for elem in df.columns if '.' in elem]\n",
    "df = df.drop(columns = columns_duplicated)\n",
    "df = df[df.index.to_series().dt.dayofweek.isin([2])]\n",
    "\n",
    "# Rounding the data to the second decimal that is the minimum ticker movement\n",
    "df = round(df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff73d9",
   "metadata": {},
   "source": [
    "## Finding cointegration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e39c8",
   "metadata": {},
   "source": [
    "function 'coint_all_timeframe'\n",
    "\n",
    "INPUT\n",
    "- __T__: the final time\n",
    "- __train__: the number of timestep to use as a base\n",
    "- __start__: the first timestep to start looking from (default is 0)\n",
    "- __N__: number of elements in every combination (default 2)\n",
    "\n",
    "OUTPUT\n",
    "- __combinations__: a list of all the combinations of N elements of the tickers\n",
    "- __count__: a list of the number of non-zero weights for every combination\n",
    "- __weights__: a list of lists where each list is the normalized weights (in the sense that the weight of the fisrt element of the combination is always 1) at every timestep t\n",
    "\n",
    "WORKING\n",
    "\n",
    "The function does, for every element in the combination list and for every timestep, the Johansen cointegration and if they are cointegrated appends the normalized weight in the corresponding weights place and increses by one the corresponding count, otherwise appends a zero in the corrisponding weights place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a3cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coint_all_timeframe(T, train, start = 0, N = 2):\n",
    "    index_ = [elem for elem in range(df.shape[1])]\n",
    "    combinations = list(itertools.combinations(index_, N))\n",
    "    combinations = [list(elem) for elem in combinations]\n",
    "\n",
    "    list_index = list()\n",
    "    weights = list()\n",
    "    count = list()\n",
    "\n",
    "    for elem in tqdm(combinations):\n",
    "        count_aux = 0\n",
    "        weights_aux = list()\n",
    "        i = train + start\n",
    "        \n",
    "        while i < T:\n",
    "        \n",
    "            res = cj(df.iloc[start:i, elem], 0, 1)\n",
    "            check = True\n",
    "\n",
    "            for j in range(N):\n",
    "                if res.lr1[j] < res.cvt[j][2]:\n",
    "                    check = False\n",
    "                    break\n",
    "\n",
    "            if check:\n",
    "                aux = res.evec[:,0]/res.evec[0,0]\n",
    "                count_aux += 1\n",
    "                weights_aux.append(aux[1])\n",
    "                        \n",
    "            else:\n",
    "                weights_aux.append(0.)\n",
    "            i += 1\n",
    "\n",
    "        weights.append(weights_aux)\n",
    "        count.append(count_aux)\n",
    "        \n",
    "    return combinations, count, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a941cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings, count, weights = coint_all_timeframe(df.shape[0], 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f79ed3",
   "metadata": {},
   "source": [
    "## Create Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c182bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings_list = list()\n",
    "index_list = list()\n",
    "\n",
    "n = len(pairings_list)\n",
    "T = len(weights[0])\n",
    "t = 0\n",
    "\n",
    "to_track = pd.DataFrame({'t': pd.Series(dtype='int'),\n",
    "                         'Pairings': pd.Series(dtype='object'),\n",
    "                         'Weights': pd.Series(dtype='object')})\n",
    "\n",
    "while t < T:\n",
    "    for i in tqdm(range(n)):\n",
    "        new = {'t': [t],\n",
    "           'Pairings': [pairings_list[i]],\n",
    "           'Weights': [weights[index_list[i]][t]]}\n",
    "       \n",
    "        to_track = pd.concat([to_track, pd.DataFrame(new)], ignore_index = True)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0725cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track.to_csv('to_track.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
